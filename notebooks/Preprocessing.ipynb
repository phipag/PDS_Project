{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "**This notebook serves as documentation of the Preprocessing implementation. The whole process is automated in the `nextbike.preprocessing.Preprocessor` class.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install -e .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nextbike.preprocessing import Preprocessor\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "import contextily as ctx\n",
    "import numpy as np\n",
    "import requests\n",
    "import io\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data set directly as GeoDataFrame for later geo-based cleansing\n",
    "preprocessor = Preprocessor()\n",
    "preprocessor.load_gdf()\n",
    "gdf = preprocessor.gdf\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains many duplicates. Bikes cannot have two bookings at the same time. Remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "old_row_number = len(gdf)\n",
    "gdf.drop_duplicates(subset=['b_number', 'datetime'], inplace=True)\n",
    "print('Number of duplicate rows removed:', old_row_number - len(gdf))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print information about the columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gdf.info(null_counts=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inspect the NaN values for p_number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gdf[gdf.isna().any(axis=1)].sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `p_number` seems to be `NaN` while it was intended to be `0`. This is typically the case if `p_spot` is `False` which might mean that the booking is not at a known station or the validation failed due to a technical mistake. This is probably the case for the entries where `p_name != BIKE {number}`.\n",
    "\n",
    "Fill the values with `0`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, inspect the different possible values for columns of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for col in ['p_spot', 'p_number', 'p_place_type', 'trip', 'b_bike_type', 'p_bike']:\n",
    "    print(gdf[col].value_counts())\n",
    "    print('---------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`p_spot`, `p_place_type` and `p_bike` seem to have influence on each other according to their distribution.\n",
    "\n",
    "**Assumption**\n",
    "* `p_spot == True` means that it is a station trip. In this case `p_bike == False` because a station trip is the opposite of a free-floating trip.\n",
    "* `p_place_type == 0` would mean station trip and `p_place_type == 12` free-floating trip in consequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3, figsize=(16, 6), dpi=300)\n",
    "gdf['p_spot'].value_counts().plot(ax=ax1, kind='bar', title='p_spot')\n",
    "gdf['p_place_type'].value_counts().plot(ax=ax2, kind='bar', title='p_place_type')\n",
    "gdf['p_bike'].value_counts().plot(ax=ax3, kind='bar', title='p_bike')\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, try to validate the assumption."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`p_place_type` is always `12` if and only if `p_bike == True`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gdf[gdf['p_place_type'] == 12]\n",
    "gdf[(gdf['p_bike'] == True) & (gdf['p_place_type'] == 12)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`p_bike` is always `True` if `p_spot == False`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gdf[(gdf['p_bike'] == True) & (gdf['p_spot'] == False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But `p_bike` can also be `False` if `p_spot == False`. **So our hypothesis cannot be validated.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf[(gdf['p_bike'] == False) & (gdf['p_spot'] == False)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neither `p_number` nor `p_uid` is a unique identifier for `p_name`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('p_number:', len(gdf['p_number'].drop_duplicates()))\n",
    "print('p_uid:', len(gdf['p_uid'].drop_duplicates()))\n",
    "print('p_name:', len(gdf['p_name'].drop_duplicates()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **The data set shows columns with prefixes p and b. What do you think do they represent? Also try to find good assumptions for the meanings of the columns**\n",
    "    * `p_`: Place related information\n",
    "    * `b_`: Bike related information\n",
    "    * `p_spot`: True if the place is a known station, False if free-floating (with some noise)\n",
    "    * `p_place_type`: 0 if the place is a known station, 12 if free-floating (with some noise)\n",
    "    * `datetime`: Date of the booking\n",
    "    * `b_number`: Unique identifier for a bike\n",
    "    * `trip`:\n",
    "        * 'first': Indicates the first booking of a day for a bike\n",
    "        * 'last': Indicates the last booking of a day for a bike\n",
    "        * 'start': Indicates the start of a trip\n",
    "        * 'end': Inidicates the end of a trip\n",
    "    * `p_uid`: ID of the location (even though no unique identifier)\n",
    "    * `p_bikes`: Available bikes at the place\n",
    "    * `p_lat`: Latitude of the location\n",
    "    * `b_bike_type`: Type of the bike (the meaning is not clear, probably different bike versions)\n",
    "    * `p_name`: Name of the location\n",
    "    * `p_number`: Number of the location (even though no unique identifier)\n",
    "    * `p_lng`: Longitude of the location\n",
    "    * `p_bike`: True if free-floating, False if known station (with some noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **The trip column in your data set shows different values. Explain why there are not only two. Are examples with certain values for trip more informative for the analysis of mobility patterns than others?**\n",
    "    * The start/end trips are more informative in order to calculate the duration of a trip and to obtain the target data format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset contains not only trips from Mannheim but also other cities like Marburg or Heidelberg.\n",
    "\n",
    "**Idea:** Try to filter the data set by station trips at stations in Mannheim or bikes which match the `b_number` of bikes which are in Mannheim.\n",
    "\n",
    "This information can be retrieved from https://mannheim.opendatasoft.com/explore/dataset/free_bike_status."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s = requests.get('https://mannheim.opendatasoft.com/explore/dataset/free_bike_status/download/?format=csv&timezone=Europe/Berlin&lang=de&use_labels_for_header=true&csv_separator=%3B', verify=False).content\n",
    "stations_df = pd.read_csv(io.StringIO(s.decode('utf-8')), delimiter=';')\n",
    "stations_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract a set of distinct bike_numbers which are currently used in Mannheim.\n",
    "\n",
    "**Problem**: There might be old bikes in the bookings which are not used anymore or bikes from Mannheim which drove to another city which is allowed according to Nextbike's policy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bike_numbers = set()\n",
    "for number_list in stations_df['Fahrradnummern']:\n",
    "    if isinstance(number_list, str):\n",
    "        for num in number_list.split(','):\n",
    "            bike_numbers.add(num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a filtered data set according to station and `b_number`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "filtered_df = gdf[(gdf['p_uid'].isin(stations_df['uid'])) | (gdf['b_number'].isin(bike_numbers))].reset_index(drop=True)\n",
    "filtered_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Same problem as before:** start and end trip number does not match. This is probably because start trips leaving a Mannheim station are kept but the corresponding end trip was cut (or vice versa)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df['trip'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filtering with the `b_number` and stations does not work properly because trips outside of Mannheim (e.g. free-floating) are still present. It might be better to filter via the GeoJson boundary of Mannheim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Load the boundary of Mannheim as GeoJson shape and plot the real stations vs the filtered trip locations\n",
    "mannheim_boundary_gdf = gpd.read_file('../data/input/mannheim_boundary.geojson', crs='EPSG:4326')\n",
    "stations_gdf = gpd.GeoDataFrame(geometry=gpd.points_from_xy(stations_df['lng'], stations_df['lat']), crs='EPSG:4326')\n",
    "filtered_gdf = gpd.GeoDataFrame(geometry=gpd.points_from_xy(filtered_df['p_lng'], filtered_df['p_lat']), crs='EPSG:4326')\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(16, 16), dpi=300)\n",
    "\n",
    "mannheim_boundary_gdf.plot(ax=ax, alpha=.6, edgecolor='blue')\n",
    "filtered_gdf.plot(ax=ax, label='Filtered trip locations', marker='x', c='red')\n",
    "stations_gdf.plot(ax=ax, label='Real stations', c='midnightblue')\n",
    "ctx.add_basemap(ax=ax, crs='EPSG:4326')\n",
    "\n",
    "ax.set_title('Mannheim: Real stations vs. filtered trip locations')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New idea:** Exlude all trips outside of the Mannheim Polygon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mannheim_boundary_polygon = mannheim_boundary_gdf['geometry'][0]\n",
    "mannheim_boundary_polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_filtered_gdf = gdf[gdf.within(mannheim_boundary_polygon)]\n",
    "geo_filtered_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now all trips are really within Mannheim."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(4, 4), dpi=300)\n",
    "\n",
    "mannheim_boundary_gdf.plot(ax=ax, alpha=.6, edgecolor='blue')\n",
    "geo_filtered_gdf.plot(ax=ax, label='Trips in Mannheim', c='red', marker='x')\n",
    "ctx.add_basemap(ax=ax, crs='EPSG:4326')\n",
    "\n",
    "ax.set_title('Mannheim: Trips within the city')\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, there is still a mismatch between start and end trips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_filtered_gdf['trip'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data cleansing\n",
    "\n",
    "To get a clean data set where each start trip has a corresponding end trip it is necessary to identify start trips without an end trip and end trips without a start trip. This is the case if two or more start trips or respectively two or more end trips occur after each other in the data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To be more explicit about the ordering of the data and to make sure that no wrong rows are removed the data is sorted by `b_number` and within each group of `b_number` by `datetime`.\n",
    "\n",
    "This makes sure that for each bike the ordering of trips follows the time in which they occured."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "geo_filtered_gdf.sort_values(by=['b_number', 'datetime'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trips of type `first` or `last` are not relevant to detect start and end trips in our case. Remove them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_filtered_gdf = geo_filtered_gdf[(geo_filtered_gdf['trip'] != 'first') & (geo_filtered_gdf['trip'] != 'last')].reset_index(drop=True)\n",
    "geo_filtered_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How to identify wrong start or end trips?**\n",
    "Since our trips are not sorted by bike and time it is easy to detect trips without the corresponding start or end booking.\n",
    "* If two consecutive rows are of trip type `start` remove the first of them\n",
    "    * Reason: Before the next start booking an end booking must occur because the trips are sorted by time for each bike so the first row must be the one without corresponding end booking.\n",
    "* If two consecutive rows are of trip type `end` remove the last of them\n",
    "    * Reason: Two end bookings after one another mean that the second booking has no corresponding start booking because the trips are sorted by time for each bike\n",
    "    \n",
    "**What happens if the first booking of a bike is of type `end` and the last booking of the previous bike of type `start`?**\n",
    "* This is a special case and covered by the algorithm. All trips per bike have to end with an end trip and have to start with a start trip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Define a sliding window O(N) algorithm which cleans the data set by the following scheme:\n",
    "# if two consecutive rows have the same trip type:\n",
    "#   if the trip type is 'start':\n",
    "#     delete the first row of the two rows (because the end trip for the observed start trip is missing)\n",
    "#   else:\n",
    "#     delete the second row (because the start trip for the observed end trip is missing)\n",
    "def fix(df):\n",
    "    # Use numpy to execute the code in the Cython space\n",
    "    trips = np.array(df['trip'])\n",
    "    b_numbers = np.array(df['b_number'])\n",
    "    # Use a hash set for distinct O(1) insertion operations\n",
    "    delete_indices = set()\n",
    "    # Iterate until the second last index because the sliding window is constructed by the interval [i, i + 1]\n",
    "    for i in range(len(trips) - 1):\n",
    "        # Special case: The trips of one bike should not end with a trip of type 'start'\n",
    "        # and the booking of the next bike should not start with a trip of type 'end'\n",
    "        if trips[i] == 'start' and trips[i + 1] == 'end' and b_numbers[i] != b_numbers[i + 1]:\n",
    "            delete_indices.add(i)\n",
    "            delete_indices.add(i + 1)\n",
    "        if trips[i] == trips[i + 1]:\n",
    "            i_delete = i if trips[i] == 'start' else i + 1\n",
    "            delete_indices.add(i_delete)\n",
    "    # Call pandas' internal drop method once in the end to hand over the execution to Cython again\n",
    "    return df.drop(delete_indices, axis=0)\n",
    "    \n",
    "geo_cleaned_gdf = fix(geo_filtered_gdf)\n",
    "geo_cleaned_gdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now each start trip has a corresponding end trip."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_cleaned_gdf['trip'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the number of rows removed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(geo_filtered_gdf) - len(geo_cleaned_gdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new data looks good now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size = 20\n",
    "random_start = np.random.randint(sample_size, len(geo_cleaned_gdf) - sample_size)\n",
    "geo_cleaned_gdf[random_start:random_start + sample_size]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split the cleaned data frame into start trips and end trips."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_gdf = geo_cleaned_gdf[geo_cleaned_gdf['trip'] == 'start'].reset_index(drop=True)\n",
    "start_gdf.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_gdf = geo_cleaned_gdf[geo_cleaned_gdf['trip'] == 'end'].reset_index(drop=True)\n",
    "end_gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each start trip has its corresponding end trip at the same index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "len(start_gdf[end_gdf['b_number'] != start_gdf['b_number']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an empty GeoDataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_gdf = gpd.GeoDataFrame(crs='EPSG:4326')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, use the data of the splitted data frames to calucate the target data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_gdf['bike_number'] = start_gdf['b_number']\n",
    "transformed_gdf['start_time'] = start_gdf['datetime']\n",
    "transformed_gdf['weekend'] = start_gdf['datetime'].dt.dayofweek // 5 == 1\n",
    "transformed_gdf['start_position'] = start_gdf['geometry']\n",
    "transformed_gdf['duration'] = end_gdf['datetime'] - start_gdf['datetime']\n",
    "transformed_gdf['end_time'] = end_gdf['datetime']\n",
    "transformed_gdf['end_position'] = end_gdf['geometry']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_gdf.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_gdf.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate statistics for `duration`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_gdf['duration'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duration_seconds = np.array(transformed_gdf['duration'].dt.seconds)\n",
    "duration_weekend_seconds = np.array(transformed_gdf[transformed_gdf['weekend'] == True]['duration'].dt.seconds)\n",
    "duration_weekday_seconds = np.array(transformed_gdf[transformed_gdf['weekend'] == False]['duration'].dt.seconds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1, ncols=1, dpi=300, figsize=(4, 3))\n",
    "ax.bar(x='Overall', height=duration_seconds.mean())\n",
    "ax.bar(x='Weekend', height=duration_weekend_seconds.mean())\n",
    "ax.bar(x='Weekday', height=duration_weekday_seconds.mean())\n",
    "ax.set_title('Mean of duration in seconds')\n",
    "ax.set_ylabel('Seconds')\n",
    "ax.set_xlabel('Scope')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
